{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount google drive to access the data"
      ],
      "metadata": {
        "id": "aomTSOlCo8P2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SzxixxicBSv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "L6YbudkGpEVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install arabert\n",
        "!pip install camel-tools\n",
        "!pip install accelerate -U\n",
        "!pip install transformers[torch]\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "A92YvEWjpD2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a transformers dataset"
      ],
      "metadata": {
        "id": "mTqureNNp5Zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import the required modules"
      ],
      "metadata": {
        "id": "dAVXEUMeiEBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from csv import DictReader\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "from camel_tools.utils.normalize import normalize_unicode\n",
        "from camel_tools.utils.normalize import normalize_alef_maksura_ar\n",
        "from camel_tools.utils.normalize import normalize_alef_ar\n",
        "from camel_tools.utils.normalize import normalize_teh_marbuta_ar"
      ],
      "metadata": {
        "id": "t6XIhTcRzcQE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Define helper functions"
      ],
      "metadata": {
        "id": "0bz0K_8PiJCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = set(open('/content/drive/MyDrive/AIC-ICMTC/dataset/arabic_stopwords.txt').read().split())\n",
        "preprocessor = ArabertPreprocessor('aubmindlab/bert-base-arabertv2')\n",
        "\n",
        "def filter_stopwords(text):\n",
        "  return ' '.join(word for word in text.split() if word not in stopwords)\n",
        "\n",
        "def preprocess_text(text):\n",
        "  return normalize_teh_marbuta_ar(\n",
        "      normalize_alef_maksura_ar(\n",
        "          normalize_alef_ar(\n",
        "              normalize_unicode(\n",
        "                  preprocessor.preprocess(\n",
        "                      filter_stopwords(\n",
        "                          text\n",
        "                      )\n",
        "                  )\n",
        "              )\n",
        "          )\n",
        "      )\n",
        "  )"
      ],
      "metadata": {
        "id": "QQNpdu0OU57m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Read the data"
      ],
      "metadata": {
        "id": "_EuYzINpiRjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {'text': [], 'summary': []}\n",
        "\n",
        "with open('/content/drive/MyDrive/AIC-ICMTC/dataset/ArabicMogalad_Ndeef.csv') as file:\n",
        "  reader = DictReader(file)\n",
        "\n",
        "  for row in reader:\n",
        "    dataset['text'].append(row.pop('Text').strip())\n",
        "    dataset['summary'].append(row.pop('Summary').strip())"
      ],
      "metadata": {
        "id": "t5TV2rdVp3Zz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Convert to a transformers dataset"
      ],
      "metadata": {
        "id": "ZNdNHpeziT6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_dict(dataset)\n",
        "dataset = dataset.train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "id": "52Yrt5h00F1F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "ZRgqY0zQSjEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning AraGPT2"
      ],
      "metadata": {
        "id": "bOfzw3Bc0gKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import the required modules"
      ],
      "metadata": {
        "id": "2LAU9UldLGgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import GPT2TokenizerFast\n",
        "from arabert.aragpt2.grover.modeling_gpt2 import GPT2LMHeadModel\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from evaluate import load\n",
        "from numpy import where\n",
        "from numpy import count_nonzero\n",
        "from numpy import mean"
      ],
      "metadata": {
        "id": "Bo30Eu_-0ttv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Initialize the model"
      ],
      "metadata": {
        "id": "1acFjhi6LL70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'aubmindlab/aragpt2-base'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)\n",
        "\n",
        "rouge = load('rouge')"
      ],
      "metadata": {
        "id": "AC2WS1e-0w46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Define helper functions"
      ],
      "metadata": {
        "id": "hpKhyFyeLPgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_for_model(examples):\n",
        "  inputs = ['summarize: ' + doc for doc in examples['text']]\n",
        "  model_inputs = tokenizer(inputs, max_length=1024 * 10, truncation=True)\n",
        "\n",
        "  labels = tokenizer(text_target=examples['summary'], max_length=128 * 10, truncation=True)\n",
        "\n",
        "  model_inputs['labels'] = labels['input_ids']\n",
        "  return model_inputs\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "  labels = where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "  result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "\n",
        "  prediction_lens = [count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "  result['gen_len'] = mean(prediction_lens)\n",
        "\n",
        "  return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "MWo4c5I-_NRB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Specify the training arguments"
      ],
      "metadata": {
        "id": "Ii-DLE__LVjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(prepare_for_model, batched=True)"
      ],
      "metadata": {
        "id": "JU8GuPJgkxn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/AIC-ICMTC/models/AraGPT2',\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy='epoch',\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    num_train_epochs=4,\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=2,\n",
        "    predict_with_generate=True\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['test'],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "ygQuotC1_Rpv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Train the model"
      ],
      "metadata": {
        "id": "NWdhB2bhLa8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Z9yM7TKz_SKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "SPHxYHwDKMZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "-JgeWLKnKJ6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_pipeline = pipeline('text2text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "result = generation_pipeline(\n",
        "    '',\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    num_beams=10,\n",
        "    max_length=200,\n",
        "    top_p=0.9,\n",
        "    repetition_penalty = 3.0,\n",
        "    no_repeat_ngram_size = 3\n",
        ")"
      ],
      "metadata": {
        "id": "5NopD95JKPSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[0]['generated_text']"
      ],
      "metadata": {
        "id": "AusBlE2IKhLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZIawHqjBm49J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}